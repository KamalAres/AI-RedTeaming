import os
import time
import torch
import matplotlib.pyplot as plt

from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

#############################################
# Dataset Loader with Preprocessing
#############################################

def load_datasets(base_path, train_batch_size, test_batch_size):
    if not os.path.exists(base_path):
        raise FileNotFoundError(f"[!] Dataset path not found: {base_path}")

    # Preprocessing transforms (as per lab)
    transform = transforms.Compose([
        transforms.Resize((75, 75)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

    train_path = os.path.join(base_path, "train")
    test_path = os.path.join(base_path, "test")

    train_dataset = ImageFolder(root=train_path, transform=transform)
    test_dataset = ImageFolder(root=test_path, transform=transform)

    train_loader = DataLoader(
        train_dataset,
        batch_size=train_batch_size,
        shuffle=True,
        num_workers=2
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=test_batch_size,
        shuffle=False,
        num_workers=2
    )

    n_classes = len(train_dataset.classes)
    return train_loader, test_loader, n_classes


#############################################
# Model Definition (Adjusted for 75x75x3)
#############################################

class MalwareClassifier(torch.nn.Module):
    def __init__(self, n_classes):
        super(MalwareClassifier, self).__init__()

        self.flatten = torch.nn.Flatten()

        # 75 x 75 x 3 = 16875
        self.fc1 = torch.nn.Linear(75 * 75 * 3, 1000)
        self.relu = torch.nn.ReLU()
        self.fc2 = torch.nn.Linear(1000, n_classes)

    def forward(self, x):
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x


#############################################
# Training Utilities
#############################################

def compute_accuracy(n_correct, n_total):
    return round(100 * n_correct / n_total, 2)


def train(model, train_loader, n_epochs, verbose=False):
    model.train()

    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters())

    for epoch in range(n_epochs):
        running_loss = 0
        n_correct = 0
        n_total = 0
        start_time = time.time()

        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            _, predicted = outputs.max(1)
            n_total += labels.size(0)
            n_correct += predicted.eq(labels).sum().item()
            running_loss += loss.item()

        acc = compute_accuracy(n_correct, n_total)
        loss_avg = running_loss / len(train_loader)
        duration = int((time.time() - start_time) * 1000)

        if verbose:
            print(
                f"[i] Epoch {epoch+1}/{n_epochs} | "
                f"Acc: {acc}% | Loss: {loss_avg:.4f} | "
                f"Time: {duration} ms"
            )


#############################################
# Evaluation
#############################################

def evaluate(model, test_loader):
    model.eval()
    n_correct = 0
    n_total = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            n_total += labels.size(0)
            n_correct += predicted.eq(labels).sum().item()

    return compute_accuracy(n_correct, n_total)


#############################################
# Save Model (TorchScript)
#############################################

def save_model(model, path):
    model.eval()

    # Dummy input matching model input shape: (batch, channels, height, width)
    example_input = torch.randn(1, 3, 75, 75)

    traced_model = torch.jit.trace(model, example_input)
    traced_model.save(path)


#############################################
# Main
#############################################

def main():
    BASE_PATH = r"C:\Users\kamalares\Documents\newdata"  # ðŸ”´ UPDATE IF NEEDED
    MODEL_FILE = "malware_classifier.pth"

    TRAIN_BATCH_SIZE = 1024
    TEST_BATCH_SIZE = 1024
    N_EPOCHS = 3   # HTB recommendation

    print("[i] Loading datasets...")
    train_loader, test_loader, n_classes = load_datasets(
        BASE_PATH,
        TRAIN_BATCH_SIZE,
        TEST_BATCH_SIZE
    )

    print(f"[i] Detected {n_classes} malware classes")

    model = MalwareClassifier(n_classes)

    print("[i] Training model...")
    train(model, train_loader, N_EPOCHS, verbose=True)

    print("[i] Evaluating model...")
    accuracy = evaluate(model, test_loader)
    print(f"[i] Final inference accuracy: {accuracy}%")

    print("[i] Saving model...")
    save_model(model, MODEL_FILE)

    print(f"[âœ“] Model saved as {MODEL_FILE}")
    print("[âœ“] Ready for HTB evaluation upload")


if __name__ == "__main__":
    main()
